{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e19a12",
   "metadata": {},
   "source": [
    "# LASSO AND INDUCTIVE CONFORMAL PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8531d",
   "metadata": {},
   "source": [
    "__TASK 1:Loading the scikit-learn version of the diabetes dataset into Jupyter\n",
    "notebook using the load_diabetes function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0ad76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of Diabetes_dataset:\n",
      " dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename'])\n",
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "Diabetes= load_diabetes()\n",
    "print(\"Keys of Diabetes_dataset:\\n\", Diabetes.keys())\n",
    "print(Diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49bba4",
   "metadata": {},
   "source": [
    "__TASK 2:Splitting the dataset into the training and test sets using the function\n",
    "train_test_split in scikit-learn. Here and below using birthday\n",
    "(in the format DDMM omitting leading zeros if any) as random_state.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e1968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 10)\n",
      "(111, 10)\n",
      "(331,)\n",
      "(111,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(Diabetes['data'],Diabetes['target'],train_size=0.75,test_size=0.25,random_state=3110)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038f8ca",
   "metadata": {},
   "source": [
    "__TASK 3:Answering the following questions:\n",
    "What is the training and test R2\n",
    "for the Lasso model using the default\n",
    "parameters? How many features does this model use? What are the names\n",
    "of those features?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f811f7",
   "metadata": {},
   "source": [
    "* As we can see after running this piece of code, Lasso does quiet badly on both testing and training set.\n",
    "* This indicates we are underfitting\n",
    "* Lasso has regularization parameter, alpha that controls how strongly coeffiecients are pushed towards zero.\n",
    "* In case like this here, when we are not mentioning the value of alpha, it takes default value as 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e770564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 score in scikit-learn dataset: 0.35901908382457937\n",
      "Testing R2 score in scikit learn dataset: 0.36586111649693864\n",
      "Number of features used: 3\n",
      "[  0.           0.         325.21633113  27.0710417    0.\n",
      "   0.          -0.           0.         341.80553958   0.        ]\n",
      "All features: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "Feature  used: bmi\n",
      "Feature  used: bp\n",
      "Feature  used: s5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(X_train,y_train)\n",
    "print('Training R2 score in scikit-learn dataset:',lasso.score(X_train,y_train))\n",
    "print('Testing R2 score in scikit learn dataset:',lasso.score(X_test,y_test))\n",
    "print('Number of features used:',np.sum(lasso.coef_ !=0))\n",
    "x = lasso.coef_ \n",
    "print(x)\n",
    "print('All features:',Diabetes.feature_names)\n",
    "for i in range(len(x)):\n",
    "    if x[i] != 0:\n",
    "        print('Feature  used:',Diabetes.feature_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5482f17",
   "metadata": {},
   "source": [
    "__TASK 4:Now loading the original diabetes dataset from the web page given above. I have pasted the file in the repository but\n",
    "you can also choose the link diabetes data. Download the file\n",
    "Tab-delimited diabetes data (text file)\n",
    "by right-clicking on it. All the remaining tasks should be performed using\n",
    "this file (diabetes.data), which is the original diabetes dataset. The\n",
    "labels are given in the last column of the file diabetes.data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b58995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age       sex       bmi       map        tc       ldl       hdl  \\\n",
      "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
      "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
      "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
      "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
      "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
      "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
      "\n",
      "          tch       ltg       glu  \n",
      "0   -0.002592  0.019908 -0.017646  \n",
      "1   -0.039493 -0.068330 -0.092204  \n",
      "2   -0.002592  0.002864 -0.025930  \n",
      "3    0.034309  0.022692 -0.009362  \n",
      "4   -0.002592 -0.031991 -0.046641  \n",
      "..        ...       ...       ...  \n",
      "437 -0.002592  0.031193  0.007207  \n",
      "438  0.034309 -0.018118  0.044485  \n",
      "439 -0.011080 -0.046879  0.015491  \n",
      "440  0.026560  0.044528 -0.025930  \n",
      "441 -0.039493 -0.004220  0.003064  \n",
      "\n",
      "[442 rows x 10 columns]\n",
      "       y\n",
      "0    151\n",
      "1     75\n",
      "2    141\n",
      "3    206\n",
      "4    135\n",
      "..   ...\n",
      "437  178\n",
      "438  104\n",
      "439  132\n",
      "440  220\n",
      "441   57\n",
      "\n",
      "[442 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(\"diabetes.txt\",delim_whitespace=True)\n",
    "features= dataset.iloc[:,0:10]\n",
    "Labels= dataset.iloc[:,10:11]\n",
    "print(features)\n",
    "print(Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb516a",
   "metadata": {},
   "source": [
    "__TASK 5:Splitting the dataset into the training and test sets using my birthday (in the\n",
    "format DDMM) as random_state.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "239fd8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 10)\n",
      "(111, 10)\n",
      "(331, 1)\n",
      "(111, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_XX,test_XX,train_yy,test_yy= train_test_split(features,Labels,train_size=0.75,test_size=0.25,random_state=3110)\n",
    "print(train_XX.shape)\n",
    "print(test_XX.shape)\n",
    "print(train_yy.shape)\n",
    "print(test_yy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844341f",
   "metadata": {},
   "source": [
    "__TASK 6:Repeat item 3 for the current dataset and Commenting on the differences from\n",
    "what we observe in item 3.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3c565",
   "metadata": {},
   "source": [
    "* The main difference here in task 3 and 6 are:\n",
    "* The training and testing R2 score is improving as the dataset changes\n",
    "* further more Lasso is only using 2 features in Task 3 and make all other as zero while it's using all features in task 6.\n",
    "* This is what is known as a form of **automatic feature selection**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63c4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 score in Original Dataset: 0.35901908382457937\n",
      "Testing R2 score in Original Dataset: 0.36586111649693864\n",
      "Number of features used: 3\n",
      "[  0.           0.         325.21633113  27.0710417    0.\n",
      "   0.          -0.           0.         341.80553958   0.        ]\n",
      "All features: Index(['age', 'sex', 'bmi', 'map', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu',\n",
      "       'y'],\n",
      "      dtype='object')\n",
      "Feature  used: bmi\n",
      "Feature  used: map\n",
      "Feature  used: ltg\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_new = Lasso().fit(train_XX,train_yy)\n",
    "print('Training R2 score in Original Dataset:',lasso_new.score(train_XX,train_yy))\n",
    "print('Testing R2 score in Original Dataset:',lasso_new.score(test_XX,test_yy))\n",
    "print('Number of features used:',np.sum(lasso_new.coef_ !=0))\n",
    "x = lasso_new.coef_ \n",
    "print(x)\n",
    "print('All features:',dataset.columns)\n",
    "for i in range(len(x)):\n",
    "    if x[i] != 0:\n",
    "        print('Feature  used:',dataset.columns[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d056b2",
   "metadata": {},
   "source": [
    "__TASK 7:Preprocessing the training and test sets in the same way and avoiding data\n",
    "snooping. Using StandardScaler.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828d488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.23866383  1.06559086  0.73719364 ...  2.96009726  0.96715684\n",
      "   0.97189782]\n",
      " [-0.79014377  1.06559086  1.48354327 ...  1.46348122  1.067754\n",
      "   1.39630175]\n",
      " [-0.27573997 -0.93844649  1.25737671 ...  0.6924972   1.49665046\n",
      "   0.12308996]\n",
      " ...\n",
      " [-1.89243763  1.06559086 -1.90895504 ... -0.06336949  0.50354771\n",
      "   0.03820918]\n",
      " [ 0.01820505 -0.93844649 -0.19008923 ... -0.81923617 -1.40559502\n",
      "  -1.15012182]\n",
      " [ 0.16517757 -0.93844649 -0.48410575 ... -1.46172286 -1.36751198\n",
      "  -0.81059868]]\n",
      "[[ 0.36677355 -0.93880559  0.52874303 ... -0.87198995  1.11934022\n",
      "  -0.51405156]\n",
      " [-0.42289623 -0.93880559  2.10325424 ... -0.02517556  1.25688278\n",
      "   1.01008128]\n",
      " [-2.17771796 -0.93880559 -1.68470027 ... -1.71880433 -1.27540272\n",
      "  -0.41879326]\n",
      " ...\n",
      " [ 0.45451464 -0.93880559  0.59720003 ... -0.74496779 -0.97732242\n",
      "  -0.51405156]\n",
      " [ 0.7177379  -0.93880559  1.0992181  ...  1.24504601 -1.00810834\n",
      "  -0.03776005]\n",
      " [ 0.36677355  1.06518326 -0.3840171  ...  0.82163882 -0.06347527\n",
      "  -0.13301835]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_XX)\n",
    "test_X_scaled = scaler.fit_transform(test_XX)\n",
    "print(train_X_scaled)\n",
    "print(test_X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b30bb",
   "metadata": {},
   "source": [
    "__TASK 8:Repeat item 3 for the current training and test sets.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a158dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 score in Normalized data: 0.5220790901067937\n",
      "Testing R2 score in Normalized data: 0.486463719094818\n",
      "Number of features used: 9\n",
      "[ -0.59025591  -8.8850563   22.63918114  14.21799327  -8.28617402\n",
      "  -0.         -10.18440253   2.18496366  26.14063185   4.07861648]\n",
      "All features: Index(['age', 'sex', 'bmi', 'map', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu',\n",
      "       'y'],\n",
      "      dtype='object')\n",
      "Feature  used: age\n",
      "Feature  used: sex\n",
      "Feature  used: bmi\n",
      "Feature  used: map\n",
      "Feature  used: tc\n",
      "No feature used\n",
      "Feature  used: hdl\n",
      "Feature  used: tch\n",
      "Feature  used: ltg\n",
      "Feature  used: glu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_2 = Lasso().fit(train_X_scaled,train_yy)\n",
    "print('Training R2 score in Normalized data:',lasso_2.score(train_X_scaled,train_yy))\n",
    "print('Testing R2 score in Normalized data:',lasso_2.score(test_X_scaled,test_yy))\n",
    "print('Number of features used:',np.sum(lasso_2.coef_ !=0))\n",
    "x = lasso_2.coef_ \n",
    "print(x)\n",
    "print('All features:',dataset.columns)\n",
    "for i in range(len(x)):\n",
    "    if x[i] != 0:\n",
    "        print('Feature  used:',dataset.columns[i])\n",
    "    else:\n",
    "        print('No feature used')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10ee22",
   "metadata": {},
   "source": [
    "__Are our current results closer to those in item 3 or\n",
    "item 6? Notice that a priori you would expect your current results to be\n",
    "closer to those in item 3, since the reason for different results in items 3\n",
    "and 6 was that the former were for normalized data while the latter were\n",
    "for the original data. Is this expectation confirmed? If not, why?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb31b7",
   "metadata": {},
   "source": [
    "* No, The expectation is not confirmed in my case\n",
    "* If we have a large amount of features and expect only few of them to be important then, Lasso might be a better choice.\n",
    "* It could be the case that Lasso here is making even important features as zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf00053",
   "metadata": {},
   "source": [
    "__TASK 9:Varying the regularization parameter α in the Lasso, plotting the test R2 vs\n",
    "the number of features used (i.e., those with non-zero coefficients).__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329caa9",
   "metadata": {},
   "source": [
    "* I will prefer the value 7(Number of features used). Due to L1 regularization, Lasso has made 3 of the coefficient equal 0\n",
    "* At this point R2 value is more close to 1.\n",
    "* Here also I think value of alpha is optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfb78b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\AppData\\Local\\Temp/ipykernel_49880/311076048.py:5: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso01 = Lasso(alpha=x,max_iter=100000).fit(train_X_scaled,train_yy)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 468502.67792277824, tolerance: 197.63306163141993\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f037e858e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def LASSO(x):\n",
    "    lasso01 = Lasso(alpha=x,max_iter=100000).fit(train_X_scaled,train_yy)\n",
    "    return round(lasso01.score(test_X_scaled,test_yy),3),np.sum(lasso01.coef_ !=0)\n",
    "alphas=[0,0.0001,0.001, 0.01, 0.1, 2,5,7,10]\n",
    "x_plot=[]\n",
    "y_plot=[]\n",
    "for i in alphas:\n",
    "    x_cord,y_cord=LASSO(i)\n",
    "    y_plot.append(y_cord)\n",
    "    x_plot.append(x_cord)\n",
    "\n",
    "plt.plot(y_plot,x_plot, label=\"Test Accuracy\")\n",
    "plt.ylabel(\"R2 Values\")\n",
    "plt.xlabel(\"Number of feature used\")\n",
    "plt.legend(ncol=2,loc=(0,1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab9b9d",
   "metadata": {},
   "source": [
    "__TASK 10:Choosing the regularization parameter for the Lasso using cross-validation\n",
    "on the training set. Training the Lasso on the whole training set using the\n",
    "chosen values of the parameters. Reporting the resulting training and test\n",
    "R2 and the number of features used.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8746379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 414475.3557116703, tolerance: 170.20219461279464\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 425173.0026946971, tolerance: 176.28835302013425\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 408922.9790691333, tolerance: 180.71450201342284\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 408277.34797401115, tolerance: 178.94595973154364\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411789.88658734644, tolerance: 173.31915201342284\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 425696.91322418884, tolerance: 180.68298959731544\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 423426.0828346512, tolerance: 178.77626208053692\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 419520.94865550415, tolerance: 179.70875872483222\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 431190.53534784645, tolerance: 175.55651174496646\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:598: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 score: 0.4889181200589179\n",
      "Best value of Alpha: {'alpha': 2, 'max_iter': 100000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 433379.16870784794, tolerance: 183.55655201342284\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0,0.0001,0.001, 0.01, 0.1, 2,5,7,10],\n",
    "             'max_iter':[100000]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv=10)\n",
    "grid_search.fit(train_X_scaled,train_yy)\n",
    "print('Training R2 score:',grid_search.score(test_X_scaled,test_yy))\n",
    "print('Best value of Alpha:',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa24fda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 score in Normalized data: 0.5170699623448385\n",
      "Testing R2 score in Normalized data: 0.4889181200589179\n",
      "Number of features used: 7\n",
      "[ -0.          -6.9564373   22.28265837  13.10046504  -4.99978044\n",
      "  -0.         -11.26541592   0.          24.99350176   3.08585468]\n",
      "All features: Index(['age', 'sex', 'bmi', 'map', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu',\n",
      "       'y'],\n",
      "      dtype='object')\n",
      "No feature used\n",
      "Feature  used: sex\n",
      "Feature  used: bmi\n",
      "Feature  used: map\n",
      "Feature  used: tc\n",
      "No feature used\n",
      "Feature  used: hdl\n",
      "No feature used\n",
      "Feature  used: ltg\n",
      "Feature  used: glu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_best = Lasso(alpha=2).fit(train_X_scaled,train_yy)\n",
    "print('Training R2 score in Normalized data:',lasso_best.score(train_X_scaled,train_yy))\n",
    "print('Testing R2 score in Normalized data:',lasso_best.score(test_X_scaled,test_yy))\n",
    "print('Number of features used:',np.sum(lasso_best.coef_ !=0))\n",
    "x = lasso_best.coef_ \n",
    "print(x)\n",
    "print('All features:',dataset.columns)\n",
    "for i in range(len(x)):\n",
    "    if x[i] != 0:\n",
    "        print('Feature  used:',dataset.columns[i])\n",
    "    else:\n",
    "        print('No feature used')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd309c91",
   "metadata": {},
   "source": [
    "__<h1>Task 11:Implementing an inductive conformal predictor as follows:</h1>__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10279793",
   "metadata": {},
   "source": [
    "__(a) Splitting the training set that we obtained in item 5 into two parts:\n",
    "the calibration set of size 99 and the rest of the training set (the\n",
    "training set proper). Using birthday (in the format DDMM) as\n",
    "random_state.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f48cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 10)\n",
      "(99, 10)\n",
      "(232, 1)\n",
      "(99, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_proper, X_calibration, y_train_proper, y_calibration= train_test_split(train_XX,train_yy,test_size=99,random_state=3110)\n",
    "print(X_train_proper.shape)\n",
    "print(X_calibration.shape)\n",
    "print(y_train_proper.shape)\n",
    "print(y_calibration.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ca3be",
   "metadata": {},
   "source": [
    "__(b) Preprocessing the training set proper, calibration set, and test set in\n",
    "the same way using StandardScaler. Namely, fit the scaler to the\n",
    "training set proper and then use it to transform all three.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4f923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_new = StandardScaler()\n",
    "scaler_new.fit(X_train_proper)\n",
    "X_train_proper_scaled = scaler_new.transform(X_train_proper)\n",
    "X_calibration_scaled = scaler_new.transform(X_calibration)\n",
    "test_X_scaled = scaler.fit_transform(test_XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c3516",
   "metadata": {},
   "source": [
    "__(c)Using the nonconformity measure α = |y − yˆ|, where y is the true\n",
    "label and ˆy is its prediction given the training set proper, for each test\n",
    "sample computing the prediction interval for it. Doing this for significance\n",
    "levels 5% and 20%. For each of these significance levels also computing:\n",
    " the length of the prediction intervals for the test samples\n",
    " and the test error rate of our inductive conformal predictor\n",
    ".__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339d3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_train_proper_scaled,y_train_proper,X_calibration_scaled,y_calibration):\n",
    "    lasso_final = Lasso(alpha=2).fit(X_train_proper_scaled,y_train_proper)\n",
    "    print('Training R2 score in Normalized data:',lasso_final.score(X_train_proper_scaled,y_train_proper))\n",
    "    y_hat =lasso_final.predict(X_calibration_scaled)\n",
    "    result=[]\n",
    "    array1 = np.array(y_calibration)\n",
    "    array2 = np.array(y_hat)\n",
    "    for i in range(len(array1)):\n",
    "        result.append(array1[i]-array2[i])\n",
    "    result=np.concatenate(result, axis=0)\n",
    "    print('Different values of alpha:',np.absolute(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21fdccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 score in Normalized data: 0.5355551717842536\n",
      "Different values of alpha: [  9.31425019  11.33576051 119.32931757 119.08430716  95.075688\n",
      "  11.09435999   8.61606448  92.81954955  87.03952306  19.8397432\n",
      "  96.16714722 103.65951103  47.97775047  14.38168549  91.61270174\n",
      "  17.09949025  12.49284524  38.24454669   1.54655344  63.25704931\n",
      "  23.66465778  18.39933036   9.0104915   57.48650293  15.6137564\n",
      "  23.55399711  49.36258561  38.70687005  12.48660788  26.30026549\n",
      "  39.5947327   20.69734215  97.00149191  32.28396319  67.50336744\n",
      "  99.30243938  88.46984057 139.20483026  62.09996911  58.14746608\n",
      "  21.97326938  74.80294043  67.83805601 105.72279168   8.74458578\n",
      "  25.51800744   2.4842174  112.91645353   4.89274753  12.44076843\n",
      "  19.30509109  21.08198894  15.71869249  98.99282772  88.57634281\n",
      "  71.60539762  43.18336269   4.57492578  28.24475884  37.54482519\n",
      "  29.35468165  41.79480795  33.57098907  81.61169285  70.53922046\n",
      "  54.14441098  30.37248344  41.51423974  32.73889493  50.50426747\n",
      "  14.64835951  19.68242135  10.13367809  63.47464045  66.67061046\n",
      "  91.33748733  10.56535882  20.16715559  25.5018316    6.05994589\n",
      "  42.12091614  89.80548654 156.17531735  47.98251911  36.91841034\n",
      "  27.10226029  56.98878939  93.75375484  26.2809813   55.86618974\n",
      "  15.16767115  42.05100763  70.04883238  42.13948544  39.19129367\n",
      "  58.06254535  52.75728698  85.31830037   4.74063228]\n"
     ]
    }
   ],
   "source": [
    "prediction(X_train_proper_scaled,y_train_proper,X_calibration_scaled,y_calibration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
